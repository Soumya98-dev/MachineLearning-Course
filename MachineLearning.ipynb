{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMABlNXRcgcYa6AuwF8r5VP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soumya98-dev/MachineLearning-Course/blob/main/MachineLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vyxJpD1I7pQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview of machine learning\n",
        "\n",
        "## Supervised\n",
        " - Maps Input(X) to Output(Y)\n",
        " - Regression\n",
        "    - Predict a number from infintely many possible outputs\n",
        "  - Classification\n",
        "    - Predict categories from small number of possible outputs\n",
        "\n",
        "## Unsupervised\n",
        "  - finding something interesting in an unlabeled data\n",
        "  - Clustering\n",
        "    - group related stuff together\n",
        "  - Anomaly deterction\n",
        "    - find unusual data points\n",
        "  - Dimensionality reduction\n",
        "    - compress data using fewer numbers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Machine Learning Process\n",
        "\n",
        "## Data- Preprocessing\n",
        "  - Import the data\n",
        "  - Clean the data\n",
        "  - Split into training & test sets\n",
        "\n",
        "## Modelling\n",
        "  - Build the model\n",
        "  - train the model\n",
        "  - make predictions\n",
        "\n",
        "## Evaluation\n",
        "  - Calculate performance metrics\n",
        "  - make a verdict\n",
        "\n",
        "## Training & Test data\n",
        "  From the whole data only 20% of the data from the original dataset we take as a test data\n",
        "  ***Train(80%), Test(20%)***\n",
        "\n",
        "## Feature Scaling\n",
        "  - Always applied to columns; never to data inside a row\n",
        "  - Normalization\n",
        "    - Taking the minimum in the column\n",
        "    - subtracting that minimum from every single value inside that column\n",
        "    - then dividing by the diference between the max & min\n",
        "    - X' = X - X(min) / X(max) - X(min)\n",
        "   - Standardization\n",
        "    - Subtract the avg\n",
        "    - X' = X - meu / sigma\n",
        "\n",
        "## Data Preprocessing\n",
        "  - Importing the libraries\n",
        "  ```py\n",
        "    import numpy as mp\n",
        "    import matplotlib.pyplot as plt\n",
        "    import pandas as pd\n",
        "  ```\n",
        "    - numpy -> arrays\n",
        "    - matplotlib - plot charts\n",
        "    - pandas - create matrix, dependent variable vector ,...\n",
        "  - Importing datset\n",
        "  - features(independent variable) are the columns with which we are going to predict the dependent variable.\n",
        "  - iloc: all the rows\n",
        "    - create a dataframe first\n",
        "      ```py\n",
        "        dataset = pd.read_csv('Data.csv')\n",
        "        # taking all the columns\n",
        "        #iloc is a method in pandas that allows you to select rows and columns in a DataFrame using integer-based indexing\n",
        "        #:, -> from 0 and :-1(excluding -1) -> till last item\n",
        "        # X is only the features(independent variable)\n",
        "        X = dataset.iloc[:, :-1].values\n",
        "        # only the last column(dependent variable)\n",
        "        y = dataset.iloc[:, -1].values\n",
        "      ```\n",
        "  - Taking care of missing data(by mean)\n",
        "  ```py\n",
        "  from sklearn.impute import SimpleImputer\n",
        "  #np.nan : from the numpy package we are using the 'nan' method\n",
        "  #nan method denotes not a number which finds the missing value and replaces with mean\n",
        "  imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
        "  #selecting the data using the 'fit' method on which columns we want to take care of missing data\n",
        "  imputer.fit(X[:, 1:3])\n",
        "  #the 'transform' method changes the the columns which we selected using the 'fit' method.\n",
        "  #It also returns the columns.\n",
        "  X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
        "  ```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "78uNOwmL7vtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coding Exercise 1: Importing and Preprocessing a Dataset for Machine Learning"
      ],
      "metadata": {
        "id": "4qpPs5u-axGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "5ilnwa8e7w61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the dataset(iris)\n",
        "dataset = pd.read_csv('Iris.csv')"
      ],
      "metadata": {
        "id": "G11hR0IRdUSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the matrix of features (X) and the dependent variable vector (y)\n",
        "#features (independent variables) in the Iris dataset are the lengths and widths\n",
        "#of the petals and sepals, and the dependent variable is the species of the Iris.\n",
        "X = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values\n"
      ],
      "metadata": {
        "id": "GJZUp4tMeaEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "9S3zkQvyhNSI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}